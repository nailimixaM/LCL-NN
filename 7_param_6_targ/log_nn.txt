Train size: 1359520
Test size: 339880


NN details:
Net(
  (fc1): Linear(in_features=1080, out_features=480, bias=True)
  (fc2): Linear(in_features=480, out_features=200, bias=True)
  (fc3): Linear(in_features=200, out_features=100, bias=True)
  (fc4): Linear(in_features=100, out_features=6, bias=True)
)


Beginning training...
[epoch 1] train loss: 0.20072919992008184,	test loss: 0.16929791092991728
[epoch 2] train loss: 0.1566138525177446,	test loss: 0.14478818647712938
[epoch 3] train loss: 0.13723866478517957,	test loss: 0.13486307469302342
[epoch 4] train loss: 0.12328498619222988,	test loss: 0.11557920052848505
[epoch 5] train loss: 0.11415943058052665,	test loss: 0.10713740441251789
[epoch 6] train loss: 0.10779425181750943,	test loss: 0.10223782265817571
[epoch 7] train loss: 0.1029114559000336,	test loss: 0.1021257904773921
[epoch 8] train loss: 0.09918425562193126,	test loss: 0.09462503397142916
[epoch 9] train loss: 0.09548060760906832,	test loss: 0.091611587804225
[epoch 10] train loss: 0.09288364730466937,	test loss: 0.09115681941059672
[epoch 11] train loss: 0.0903819952709736,	test loss: 0.09525750084342366
[epoch 12] train loss: 0.08791775130441756,	test loss: 0.08604538387885531
[epoch 13] train loss: 0.08588046129568469,	test loss: 0.08239747941875601
[epoch 14] train loss: 0.08387796559281294,	test loss: 0.0920415826922846
[epoch 15] train loss: 0.08269821907582421,	test loss: 0.08207422839364412
[epoch 16] train loss: 0.08095807042001624,	test loss: 0.08334266729425654
[epoch 17] train loss: 0.07989240953989062,	test loss: 0.07583357745797353
[epoch 18] train loss: 0.07817524244382408,	test loss: 0.07932204253099248
[epoch 19] train loss: 0.07732361416000856,	test loss: 0.07842024014969806
[epoch 20] train loss: 0.07609528498333366,	test loss: 0.07810469708191801
[epoch 21] train loss: 0.07504291636140324,	test loss: 0.07829663257982412
[epoch 22] train loss: 0.07427951882822774,	test loss: 0.07149513280791917
[epoch 23] train loss: 0.07332720969913606,	test loss: 0.08027979028645983
[epoch 24] train loss: 0.07285265597712878,	test loss: 0.07102850976903308
[epoch 25] train loss: 0.07157832717084242,	test loss: 0.07053327211835851
[epoch 26] train loss: 0.07093878523333216,	test loss: 0.07103791251961421
[epoch 27] train loss: 0.07097970629885131,	test loss: 0.06982509428189919
[epoch 28] train loss: 0.0704528608827139,	test loss: 0.0716161590193688
[epoch 29] train loss: 0.06908109318141252,	test loss: 0.06889368284822493
[epoch 30] train loss: 0.06884312235734692,	test loss: 0.06725868445254278
[epoch 31] train loss: 0.06827284403107269,	test loss: 0.06575576063671877
[epoch 32] train loss: 0.06741773334547094,	test loss: 0.06627739320497839
[epoch 33] train loss: 0.06681265680144528,	test loss: 0.07506705942514486
[epoch 34] train loss: 0.06642514100178432,	test loss: 0.06654926665772225
[epoch 35] train loss: 0.06611442748790147,	test loss: 0.06418492229116919
[epoch 36] train loss: 0.06569398675039918,	test loss: 0.06385689509034538
[epoch 37] train loss: 0.06517217477002822,	test loss: 0.06933317382047266
[epoch 38] train loss: 0.06478404666626161,	test loss: 0.06993242900936862
[epoch 39] train loss: 0.0642441409404471,	test loss: 0.0668812720057146
[epoch 40] train loss: 0.06367415580395686,	test loss: 0.06369426070356847
[epoch 41] train loss: 0.06370163101698528,	test loss: 0.06412063436536147
[epoch 42] train loss: 0.06305595242616818,	test loss: 0.06494095110921502
[epoch 43] train loss: 0.06284665617926934,	test loss: 0.0619479561773555
[epoch 44] train loss: 0.06252315387685703,	test loss: 0.06073273510454859
[epoch 45] train loss: 0.06206648207016601,	test loss: 0.06007246426705134
[epoch 46] train loss: 0.06172255737671196,	test loss: 0.06346807194594875
[epoch 47] train loss: 0.061780381221748816,	test loss: 0.05783901396725495
[epoch 48] train loss: 0.06106533764620737,	test loss: 0.06151684058085937
[epoch 49] train loss: 0.06063674769210776,	test loss: 0.061375142270068586
[epoch 50] train loss: 0.060539300929371334,	test loss: 0.05909622454271283
[epoch 51] train loss: 0.060226259531661594,	test loss: 0.05751787239804409
[epoch 52] train loss: 0.06000020374241847,	test loss: 0.05739884311598377
[epoch 53] train loss: 0.05961669280343999,	test loss: 0.05748264912313652
[epoch 54] train loss: 0.05957199114001816,	test loss: 0.05905571524146368
[epoch 55] train loss: 0.05930616153361552,	test loss: 0.06098747004192652
[epoch 56] train loss: 0.0587940856164625,	test loss: 0.05644126876096019
[epoch 57] train loss: 0.05876674722320189,	test loss: 0.05650793266549174
[epoch 58] train loss: 0.05817886930216957,	test loss: 0.057831184346433175
[epoch 59] train loss: 0.05816180929211734,	test loss: 0.05856262940574716
[epoch 60] train loss: 0.058033222255429874,	test loss: 0.05899207064559471
[epoch 61] train loss: 0.057593491195439064,	test loss: 0.05487119928461968
[epoch 62] train loss: 0.057386332698813984,	test loss: 0.055590343073770754
[epoch 63] train loss: 0.05697589248548772,	test loss: 0.05594970215186813
[epoch 64] train loss: 0.05685883282785885,	test loss: 0.06048160727588876
[epoch 65] train loss: 0.05723413698926236,	test loss: 0.05492347120282985
[epoch 66] train loss: 0.05650534446206445,	test loss: 0.057829878892843765
[epoch 67] train loss: 0.05633277526252641,	test loss: 0.054269879716459815
[epoch 68] train loss: 0.055914132024461945,	test loss: 0.05569202268943807
[epoch 69] train loss: 0.055897447727149545,	test loss: 0.05458630029629794
[epoch 70] train loss: 0.055957050780656194,	test loss: 0.059813870357351716
[epoch 71] train loss: 0.05541690756109913,	test loss: 0.054673952417297146
[epoch 72] train loss: 0.055374389974193285,	test loss: 0.06198830086320292
[epoch 73] train loss: 0.05507909875114367,	test loss: 0.058456795143878325
[epoch 74] train loss: 0.05507707850563625,	test loss: 0.05263989228950273
[epoch 75] train loss: 0.054872978780584954,	test loss: 0.05415464169344427
[epoch 76] train loss: 0.054535882630118174,	test loss: 0.06019484967017496
[epoch 77] train loss: 0.05459770797774247,	test loss: 0.05826166483075097
[epoch 78] train loss: 0.05381588121133336,	test loss: 0.05550044506976614
[epoch 79] train loss: 0.05438708028843489,	test loss: 0.05298756689093607
[epoch 80] train loss: 0.054208977458223485,	test loss: 0.05680691276005252
[epoch 81] train loss: 0.053799710840385685,	test loss: 0.059479701620249695
[epoch 82] train loss: 0.0538598887674488,	test loss: 0.053105002063033015
[epoch 83] train loss: 0.05302305885062427,	test loss: 0.05375126527208056
[epoch 84] train loss: 0.053343316710506274,	test loss: 0.05329893615564942
[epoch 85] train loss: 0.053300831865613976,	test loss: 0.05008295614434988
[epoch 86] train loss: 0.053376387703170866,	test loss: 0.05618724678249575
[epoch 87] train loss: 0.05289305296330117,	test loss: 0.05414540854168247
[epoch 88] train loss: 0.05249967380788026,	test loss: 0.05192205595676158
[epoch 89] train loss: 0.05223497985198738,	test loss: 0.058528058535553824
[epoch 90] train loss: 0.05242443277533303,	test loss: 0.04892406644660447
[epoch 91] train loss: 0.05205596014408025,	test loss: 0.052970478093797874
[epoch 92] train loss: 0.05226304327129007,	test loss: 0.05214073215179484
[epoch 93] train loss: 0.052266947107099136,	test loss: 0.052535830198403737
[epoch 94] train loss: 0.05160024311989996,	test loss: 0.052165678630979775
[epoch 95] train loss: 0.051574493258774036,	test loss: 0.05395277425531394
[epoch 96] train loss: 0.051851374712831334,	test loss: 0.049098288261979935
[epoch 97] train loss: 0.05150670685490108,	test loss: 0.052024386172199726
[epoch 98] train loss: 0.051268516207901994,	test loss: 0.05118891677420082
[epoch 99] train loss: 0.05153889467504941,	test loss: 0.05551214542248666
[epoch 100] train loss: 0.05102921413038509,	test loss: 0.053006944808125143
[epoch 101] train loss: 0.050940561844003314,	test loss: 0.05088465585749671
[epoch 102] train loss: 0.050860831131397596,	test loss: 0.05011055449417879
[epoch 103] train loss: 0.051098883030338,	test loss: 0.04848555927288858
[epoch 104] train loss: 0.05067558414188533,	test loss: 0.04831295709767808
[epoch 105] train loss: 0.05054191146268909,	test loss: 0.049835254702504286
[epoch 106] train loss: 0.050449475955060434,	test loss: 0.05038751985482129
[epoch 107] train loss: 0.05035182374908826,	test loss: 0.056303298314330695
[epoch 108] train loss: 0.050241396584673574,	test loss: 0.053048364411457466
[epoch 109] train loss: 0.050076522769645526,	test loss: 0.05089006288642746
[epoch 110] train loss: 0.04997147938201535,	test loss: 0.05250544194291966
[epoch 111] train loss: 0.049750955138370294,	test loss: 0.053700817489021654
[epoch 112] train loss: 0.04972407209836943,	test loss: 0.05113644784339871
[epoch 113] train loss: 0.04959088627553682,	test loss: 0.04956197407013047
[epoch 114] train loss: 0.049476072155637235,	test loss: 0.050766902493488045
[epoch 115] train loss: 0.04965771913200255,	test loss: 0.05076502810837157
[epoch 116] train loss: 0.04977331130903488,	test loss: 0.048015737866169
[epoch 117] train loss: 0.04918975472403996,	test loss: 0.05086416076948575
[epoch 118] train loss: 0.04898548394385536,	test loss: 0.04778756824087617
[epoch 119] train loss: 0.049301540030777406,	test loss: 0.04787960926483656
[epoch 120] train loss: 0.04890778130949267,	test loss: 0.04714845688290394
[epoch 121] train loss: 0.049182300551968795,	test loss: 0.04996014359256295
[epoch 122] train loss: 0.04906972784720659,	test loss: 0.04977173821658964
[epoch 123] train loss: 0.048766268178025415,	test loss: 0.04828192947456782
[epoch 124] train loss: 0.0487661943437191,	test loss: 0.04806979958859753
[epoch 125] train loss: 0.0484599158186777,	test loss: 0.05008073224815862
[epoch 126] train loss: 0.04842012182679178,	test loss: 0.04790169219113476
[epoch 127] train loss: 0.04881603770225167,	test loss: 0.05184120556416217
[epoch 128] train loss: 0.04834407356183236,	test loss: 0.04813210442959885
[epoch 129] train loss: 0.04809697259114024,	test loss: 0.0512706270524747
[epoch 130] train loss: 0.048151251190453104,	test loss: 0.04933548527069435
[epoch 131] train loss: 0.04781522317498754,	test loss: 0.04591594340391596
[epoch 132] train loss: 0.04753882249533812,	test loss: 0.04847467722807725
[epoch 133] train loss: 0.04790590545523328,	test loss: 0.05009483295985942
[epoch 134] train loss: 0.04795581424801307,	test loss: 0.04805692462857102
[epoch 135] train loss: 0.04772278146808766,	test loss: 0.04884062512746809
[epoch 136] train loss: 0.047552937275595876,	test loss: 0.04701216757797067
[epoch 137] train loss: 0.04786769220425788,	test loss: 0.04706965312620852
[epoch 138] train loss: 0.047537864046402985,	test loss: 0.052188683311298126
[epoch 139] train loss: 0.04745411485055095,	test loss: 0.04767431690980857
[epoch 140] train loss: 0.04726759858604673,	test loss: 0.04904933264544766
[epoch 141] train loss: 0.047174036182921326,	test loss: 0.047616865592207985
[epoch 142] train loss: 0.04716866452912098,	test loss: 0.0475140099121562
[epoch 143] train loss: 0.047125227135460884,	test loss: 0.047349829386191165
[epoch 144] train loss: 0.04713095438954285,	test loss: 0.04816358987843545
[epoch 145] train loss: 0.046814670024997354,	test loss: 0.05254244114743484
[epoch 146] train loss: 0.04675582090050198,	test loss: 0.05074598095905844
[epoch 147] train loss: 0.04681552080234558,	test loss: 0.048653449430740896
[epoch 148] train loss: 0.04659511568649921,	test loss: 0.047532948447126175
[epoch 149] train loss: 0.04669283799170471,	test loss: 0.046482809197348
[epoch 150] train loss: 0.04606233352819585,	test loss: 0.04765206218555612
[epoch 151] train loss: 0.04673251249969698,	test loss: 0.04827763083199279
[epoch 152] train loss: 0.04645954935491725,	test loss: 0.04453920040752797
[epoch 153] train loss: 0.04662153279622878,	test loss: 0.047657147405930536
[epoch 154] train loss: 0.046157097773757254,	test loss: 0.04766680631689238
[epoch 155] train loss: 0.04607775388703358,	test loss: 0.0460919495018725
[epoch 156] train loss: 0.04642220570046448,	test loss: 0.04581373494180867
[epoch 157] train loss: 0.04594167552612014,	test loss: 0.046958320481193944
[epoch 158] train loss: 0.046226760261064086,	test loss: 0.04796620606193625
[epoch 159] train loss: 0.04611792206748498,	test loss: 0.04686402587962837
[epoch 160] train loss: 0.0462324887509138,	test loss: 0.04758733890185286
[epoch 161] train loss: 0.04580454938834023,	test loss: 0.049061776595884524
[epoch 162] train loss: 0.0461200234002397,	test loss: 0.050686947463499506
[epoch 163] train loss: 0.04576653905569823,	test loss: 0.04485756607596186
[epoch 164] train loss: 0.045453512816474854,	test loss: 0.04602644297937868
[epoch 165] train loss: 0.04574785232423719,	test loss: 0.04741034221222634
[epoch 166] train loss: 0.04569240896391309,	test loss: 0.046795041635546444
[epoch 167] train loss: 0.045535604923248214,	test loss: 0.045036129328047146
[epoch 168] train loss: 0.04539552972191816,	test loss: 0.046344920431401905
[epoch 169] train loss: 0.045456040589114136,	test loss: 0.04615252507281697
[epoch 170] train loss: 0.04534539580650004,	test loss: 0.043236583112354066
[epoch 171] train loss: 0.044953495347089666,	test loss: 0.045233134746045005
[epoch 172] train loss: 0.045240487799163544,	test loss: 0.047493446750379704
[epoch 173] train loss: 0.04541643230654252,	test loss: 0.048601731343809844
[epoch 174] train loss: 0.04550193269945969,	test loss: 0.049539566209612605
[epoch 175] train loss: 0.04509932597650617,	test loss: 0.04582578922048049
[epoch 176] train loss: 0.04493254794170271,	test loss: 0.043681154960129594
[epoch 177] train loss: 0.045200984405349344,	test loss: 0.043148129064453346
[epoch 178] train loss: 0.0447543837855213,	test loss: 0.04661075327314432
[epoch 179] train loss: 0.045050155808063125,	test loss: 0.050821230485769864
[epoch 180] train loss: 0.0447783152764903,	test loss: 0.04351466364623972
[epoch 181] train loss: 0.04467459155588089,	test loss: 0.04381981507500007
[epoch 182] train loss: 0.044739370095288535,	test loss: 0.04365264549351533
[epoch 183] train loss: 0.044252977162928114,	test loss: 0.04904108268724784
[epoch 184] train loss: 0.044896735328613616,	test loss: 0.042252600218914395
[epoch 185] train loss: 0.04479015815920322,	test loss: 0.04526306739186121
[epoch 186] train loss: 0.04450929522299055,	test loss: 0.045971320426208453
[epoch 187] train loss: 0.04428234894004389,	test loss: 0.04486637687290217
[epoch 188] train loss: 0.04443596787697384,	test loss: 0.044430737171400704
[epoch 189] train loss: 0.0443126070748981,	test loss: 0.04459646351375654
[epoch 190] train loss: 0.044101617232896684,	test loss: 0.04224511119530058
[epoch 191] train loss: 0.044322473631156156,	test loss: 0.043741759769524685
[epoch 192] train loss: 0.044066620928639014,	test loss: 0.04698199032687907
[epoch 193] train loss: 0.04414300093498721,	test loss: 0.044734408287628716
[epoch 194] train loss: 0.04382980500678427,	test loss: 0.04613881004817731
[epoch 195] train loss: 0.044072888160356205,	test loss: 0.046331112228828956
[epoch 196] train loss: 0.04398711373068529,	test loss: 0.04528759294585531
[epoch 197] train loss: 0.04409907628695744,	test loss: 0.04446681179775707
[epoch 198] train loss: 0.0441618163372259,	test loss: 0.04587482718005345
[epoch 199] train loss: 0.04390152421132848,	test loss: 0.047939548322007614
[epoch 200] train loss: 0.04369103828744967,	test loss: 0.04227109370308878
[epoch 201] train loss: 0.04361280704492982,	test loss: 0.04639525873190012
[epoch 202] train loss: 0.04379313657356226,	test loss: 0.046411259907636816
[epoch 203] train loss: 0.043780645493499186,	test loss: 0.04241519999142889
[epoch 204] train loss: 0.04372736735943238,	test loss: 0.04371695647966394
[epoch 205] train loss: 0.04361010449248858,	test loss: 0.045319763113171006
[epoch 206] train loss: 0.043514990181342944,	test loss: 0.0446916414839921
[epoch 207] train loss: 0.04365646383226308,	test loss: 0.04325011222720842
[epoch 208] train loss: 0.04338881381247168,	test loss: 0.04784749942525934
[epoch 209] train loss: 0.0435408352350387,	test loss: 0.04575215126835777
[epoch 210] train loss: 0.043466133866111326,	test loss: 0.04458640347073611
[epoch 211] train loss: 0.04310905930643961,	test loss: 0.04478489014322059
[epoch 212] train loss: 0.04322056382411215,	test loss: 0.042267052857578355
[epoch 213] train loss: 0.043083038526360265,	test loss: 0.04434000070903775
[epoch 214] train loss: 0.043141676600023174,	test loss: 0.0421815317036673
[epoch 215] train loss: 0.043434584812102536,	test loss: 0.04260919952683179
[epoch 216] train loss: 0.043136675079494716,	test loss: 0.04278514617577165
[epoch 217] train loss: 0.04279780945083142,	test loss: 0.04345350752685672
[epoch 218] train loss: 0.04311460714751087,	test loss: 0.04704891833439057
[epoch 219] train loss: 0.04298939672353354,	test loss: 0.04668602759981858
[epoch 220] train loss: 0.04294358414501569,	test loss: 0.04385908577100741
[epoch 221] train loss: 0.04319663283921001,	test loss: 0.04190151997527134
[epoch 222] train loss: 0.04285635011929737,	test loss: 0.04147212112958069
[epoch 223] train loss: 0.0429202926615468,	test loss: 0.043057361172689164
[epoch 224] train loss: 0.042706255962269686,	test loss: 0.0453455633732276
[epoch 225] train loss: 0.042715123641199663,	test loss: 0.043061833530412826
[epoch 226] train loss: 0.042502083858701016,	test loss: 0.04191087648993198
[epoch 227] train loss: 0.04284132910089783,	test loss: 0.04410519944157998
[epoch 228] train loss: 0.04263406785158971,	test loss: 0.04637080616735888
[epoch 229] train loss: 0.042633644391390946,	test loss: 0.04123534678798007
[epoch 230] train loss: 0.04252457662523438,	test loss: 0.04172358642808803
[epoch 231] train loss: 0.04249586350578306,	test loss: 0.04496340665385089
[epoch 232] train loss: 0.04248903213362065,	test loss: 0.042165273079530614
[epoch 233] train loss: 0.04227643926135921,	test loss: 0.041505037739532784
[epoch 234] train loss: 0.04256758096942752,	test loss: 0.04312797433330339
[epoch 235] train loss: 0.04232080218243677,	test loss: 0.04282164658014883
[epoch 236] train loss: 0.042660846591785845,	test loss: 0.04530428245343067
[epoch 237] train loss: 0.04224302957842066,	test loss: 0.04187574952639159
[epoch 238] train loss: 0.04214682593695126,	test loss: 0.04144044951553686
[epoch 239] train loss: 0.04220448043888979,	test loss: 0.045376234079194874
[epoch 240] train loss: 0.04244709823099585,	test loss: 0.04486018675778413
[epoch 241] train loss: 0.04226230935609692,	test loss: 0.04402067163404694
[epoch 242] train loss: 0.0422263764067087,	test loss: 0.04104806521751092
[epoch 243] train loss: 0.0420666770238817,	test loss: 0.04310631362289982
